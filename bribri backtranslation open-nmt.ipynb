{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "isaac backtranslation_opennmt_py_as_function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwCKRwq5CCSJ"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvmGxs1QNJ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnmbdixSK2nU"
      },
      "source": [
        "Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRNIektfK2GP"
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py\n",
        "!pip install OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6k8jjR_Lo_C"
      },
      "source": [
        "Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1RvQenhLoba"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60m2l9uGuj7J"
      },
      "source": [
        "function to save text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n56c8wy6Wwip"
      },
      "source": [
        "def saveFile(path, textFile):\n",
        "  outText = \"\"\n",
        "  for r in textFile: outText += r + \"\\r\\n\"\n",
        "  textFile = textFile[:-1]\n",
        "  with open(path, 'w') as file: file.write(outText)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuC1TIBVmXdF"
      },
      "source": [
        "functions to encode bit-pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78JOBKbBmZrH"
      },
      "source": [
        "# Spanish to Bribri\n",
        "def bpSpanishBribri():\n",
        "\n",
        "  !python OpenNMT-py/tools/learn_bpe.py -i '/content/brbnmt-train-spn.txt' -o OpenNMT-py/data/src.code -s 10000\n",
        "  !python OpenNMT-py/tools/learn_bpe.py -i '/content/brbnmt-train-brb.txt' -o OpenNMT-py/data/tgt.code -s 10000\n",
        "\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i '/content/brbnmt-train-spn.txt' -o OpenNMT-py/data/src-train-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i '/content/brbnmt-val-spn.txt' -o OpenNMT-py/data/src-val-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i '/content/brbnmt-test-spn.txt' -o OpenNMT-py/data/src-test-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i '/content/brbnmt-train-brb.txt' -o OpenNMT-py/data/tgt-train-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i '/content/brbnmt-val-brb.txt' -o OpenNMT-py/data/tgt-val-bpe.txt\n",
        "\n",
        "# Bribri to Spanish\n",
        "def bpBribriSpanish():\n",
        "\n",
        "  !python OpenNMT-py/tools/learn_bpe.py -i '/content/brbnmt-train-brb.txt' -o OpenNMT-py/data/src.code -s 10000\n",
        "  !python OpenNMT-py/tools/learn_bpe.py -i '/content/brbnmt-train-spn.txt' -o OpenNMT-py/data/tgt.code -s 10000\n",
        "\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i '/content/brbnmt-train-brb.txt' -o OpenNMT-py/data/src-train-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i '/content/brbnmt-val-brb.txt' -o OpenNMT-py/data/src-val-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i '/content/brbnmt-test-brb.txt' -o OpenNMT-py/data/src-test-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i '/content/brbnmt-train-spn.txt' -o OpenNMT-py/data/tgt-train-bpe.txt\n",
        "  !python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i '/content/brbnmt-val-spn.txt' -o OpenNMT-py/data/tgt-val-bpe.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxSq86hlmyde"
      },
      "source": [
        "functions to pre-process pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mklTdTYymz9z"
      },
      "source": [
        "def preprocessPairs():\n",
        "  !python OpenNMT-py/preprocess.py -train_src OpenNMT-py/data/src-train-bpe.txt -train_tgt OpenNMT-py/data/tgt-train-bpe.txt -valid_src OpenNMT-py/data/src-val-bpe.txt -valid_tgt OpenNMT-py/data/tgt-val-bpe.txt -save_data OpenNMT-py/data/demo -overwrite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8GnKKvWnRal"
      },
      "source": [
        "train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfvmKTRPnSvX"
      },
      "source": [
        "def trainNMT(trainSteps, validationSteps, checkpointSteps, logPath):\n",
        "\n",
        "  !python OpenNMT-py/train.py -data OpenNMT-py/data/demo -save_model OpenNMT-py/data/model/model \\\n",
        "        -layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 -encoder_type transformer \\\n",
        "        -decoder_type transformer -position_encoding -train_steps $trainSteps -max_generator_batches 2 -dropout 0.1 \\\n",
        "        -batch_size 4096 -batch_type tokens -normalization tokens -accum_count 2 -optim adam -adam_beta2 0.998 \\\n",
        "        -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot \\\n",
        "        -label_smoothing 0.1 -valid_steps $validationSteps -save_checkpoint_steps $checkpointSteps -world_size 1 -gpu_rank 0  \\\n",
        "        -log_file $logPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StdbI2JionPg"
      },
      "source": [
        "function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUT9L4WlonzK"
      },
      "source": [
        "def produceNMTTranslations(modelPath, sourcePath, logPath):\n",
        "\n",
        "  !python OpenNMT-py/translate.py -model $modelPath\t\\\n",
        "    -src $sourcePath -output OpenNMT-py/pred.txt -replace_unk -verbose \\\n",
        "    -log_file $logPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxFRFuWcppC-"
      },
      "source": [
        "get BLEU values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg_ImWxdpqPv"
      },
      "source": [
        "def getBlue(sourcePath, logPath):\n",
        "  \n",
        "  !sed -i \"s/@@ //g\"  OpenNMT-py/pred.txt\n",
        "  !perl  OpenNMT-py/tools/multi-bleu.perl $sourcePath < OpenNMT-py/pred.txt > $logPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilTldQKCAVBx"
      },
      "source": [
        "generate synthetic, back translated sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBLaMjBFAXAL"
      },
      "source": [
        "def generateSynth(modelPath, realSentences, outputPath):\n",
        "  !python OpenNMT-py/translate.py -model $modelPath\t\\\n",
        "    -src $realSentences -output $outputPath -replace_unk -verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryCV5nRkWcL-"
      },
      "source": [
        "merge synthetic sentences with real sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fayx3LMaWeMl"
      },
      "source": [
        "def mergeSynthSentences(syntheticSet):\n",
        "\n",
        "  originalBribriTrainingSet = pd.read_fwf('/content/brbnmt-train-brb-original.txt',  header=None)\n",
        "  brb_train = originalBribriTrainingSet[0]\n",
        "\n",
        "  originalSpanishTrainingSet = pd.read_fwf('/content/brbnmt-train-spn-original.txt',  header=None)\n",
        "  spa_train = originalSpanishTrainingSet[0]\n",
        "\n",
        "  #saveFile(\"/content/brbnmt-train-spn-original.txt\",spa_train)\n",
        "\n",
        "  #brb_synth1 = pd.read_fwf('/content/synth-bribri-2.txt',  header=None)\n",
        "  brb_synth1 = pd.read_fwf(syntheticSet,  header=None)\n",
        "  brb_synth1 = brb_synth1[0]\n",
        "\n",
        "  spanishBT = pd.read_fwf('/content/brbnmt-bt-spn.txt',  header=None)\n",
        "  spanishBT = spanishBT[0]\n",
        "\n",
        "  b_train_synth1 = brb_train.append(brb_synth1)\n",
        "  #print(type(b_train_synth1))\n",
        "  #print(len(b_train_synth1))\n",
        "\n",
        "  t = spa_train\n",
        "  s_train_synth1 = t.append(spanishBT)\n",
        "  #print(type(s_train_synth1))\n",
        "  #print(len(s_train_synth1))\n",
        "\n",
        "  b_train_synth1_str = \"\"\n",
        "  s_train_synth1_str = \"\"\n",
        "\n",
        "  for t in b_train_synth1: b_train_synth1_str += str(t) + \"\\r\\n\"\n",
        "  b_train_synth1_str = b_train_synth1_str[:-1]\n",
        "  with open('/content/brbnmt-train-brb.txt', 'w') as file: file.write(b_train_synth1_str)\n",
        "\n",
        "  for t in s_train_synth1: s_train_synth1_str += str(t) + \"\\r\\n\"\n",
        "  s_train_synth1_str = s_train_synth1_str[:-1]\n",
        "  with open('/content/brbnmt-train-spn.txt', 'w') as file: file.write(s_train_synth1_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee8e5skdLBY4"
      },
      "source": [
        "splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnWhyowWLBGd"
      },
      "source": [
        "def sampleSplit(pairs, useSynthData, portionRealData, trainStepsForModels, percentBT):\n",
        "\n",
        "# Get percentage of sentences that will be used for\n",
        "  # training, test, validation, and for back translation. \n",
        "  percentTest = 0.1\n",
        "  percentVal  = percentTest / (1-percentTest)\n",
        "\n",
        "  # Split the sets\n",
        "  if (useSynthData == 1):\n",
        "    auth,bt = train_test_split(pairs,test_size=percentBT,random_state=1)\n",
        "    b_train,b_test,s_train,s_test = train_test_split(auth['Source'],auth['Target'],test_size=percentTest,random_state=1)\n",
        "    b_train,b_val,s_train,s_val   = train_test_split(b_train, s_train, test_size=percentVal, random_state=1) \n",
        "  elif (useSynthData == 0):\n",
        "    b_train,b_test,s_train,s_test = train_test_split(pairs['Source'],pairs['Target'],test_size=percentTest,random_state=1)\n",
        "    b_train,b_val,s_train,s_val   = train_test_split(b_train, s_train, test_size=percentVal, random_state=1) \n",
        "\n",
        "  # get only a percentage of the set\n",
        "  cutOffRatio = portionRealData \n",
        "  if (portionRealData != 1):\n",
        "    b_train = b_train[:int(len(b_train)*cutOffRatio)]\n",
        "    b_val   = b_val[:int(len(b_val)*cutOffRatio)]\n",
        "    b_test  = b_test[:int(len(b_test)*cutOffRatio)]\n",
        "    s_train = s_train[:int(len(s_train)*cutOffRatio)]\n",
        "    s_val   = s_val[:int(len(s_val)*cutOffRatio)]\n",
        "    s_test  = s_test[:int(len(s_test)*cutOffRatio)]\n",
        "  \n",
        "  if (useSynthData == 1):\n",
        "    bt = bt[:int(len(b_train) + len(b_val) + len(b_test))]\n",
        "\n",
        "  # Save files\n",
        "  saveFile(\"/content/brbnmt-train-brb-original.txt\",b_train)\n",
        "  saveFile(\"/content/brbnmt-train-brb.txt\",b_train)\n",
        "  saveFile(\"/content/brbnmt-test-brb.txt\",b_test)\n",
        "  saveFile(\"/content/brbnmt-val-brb.txt\",b_val)\n",
        "  saveFile(\"/content/brbnmt-train-spn.txt\",s_train)\n",
        "  saveFile(\"/content/brbnmt-train-spn-original.txt\",s_train)\n",
        "  saveFile(\"/content/brbnmt-test-spn.txt\",s_test)\n",
        "  saveFile(\"/content/brbnmt-val-spn.txt\",s_val)\n",
        "\n",
        "  if (useSynthData == 1):\n",
        "    saveFile(\"/content/brbnmt-bt-spn.txt\",bt['Target'])\n",
        "    saveFile(\"/content/brbnmt-bt-brb-ref.txt\",bt['Source'])\n",
        "\n",
        "  outputMetadata = \"\\n\"\n",
        "  outputMetadata += \"Uses synthetic data:            \" + str(useSynthData) + \"\\n\"\n",
        "  outputMetadata += \"Training steps:                 \" + str(trainStepsForModels) + \"\\n\\n\"\n",
        "  outputMetadata += \"Total real samples:             \" + str(len(b_train)+len(b_val)+len(b_test)) + \"\\n\\n\"\n",
        "  outputMetadata += \"Bribri training samples:        \" + str(len(b_train)) + \"\\n\"\n",
        "  outputMetadata += \"Spanish training samples:       \" + str(len(s_train)) + \"\\n\"\n",
        "  outputMetadata += \"Bribri validation samples:      \" + str(len(b_val)) + \"\\n\"\n",
        "  outputMetadata += \"Spanish validation samples:     \" + str(len(s_val)) + \"\\n\"\n",
        "  outputMetadata += \"Bribri testing samples:         \" + str(len(b_test)) + \"\\n\"\n",
        "  outputMetadata += \"Spanish testing samples:        \" + str(len(s_test)) + \"\\n\"\n",
        "\n",
        "  if (useSynthData)  == 1:\n",
        "    outputMetadata += \"Spanish backtraslation samples: \" + str(len(bt)) + \"\\n\"\n",
        "\n",
        "  with open(\"/content/brbnmt-meta.txt\", 'w') as file: file.write(outputMetadata)\n",
        "\n",
        "  print(outputMetadata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkFlrZqpvA8C"
      },
      "source": [
        "training as a function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTRQYK-Yt86r"
      },
      "source": [
        "def runTraining(useSynthData, portionRealData, inTrainSteps, inValSteps, inCheckpointSteps, inModelName, inPercentBT):\n",
        "\n",
        "  trainStepsForModels = inTrainSteps\n",
        "  validationStepsForModels = inValSteps\n",
        "  checkpointStepsForModels = inCheckpointSteps\n",
        "  modelName = inModelName\n",
        "\n",
        "  percentBT = inPercentBT\n",
        "  #sameBase = inSameBase\n",
        "\n",
        "  # Read bitext from GitHub\n",
        "  url = 'https://raw.githubusercontent.com/rolandocoto/bribri-coling2020/main/bri-spa-pair-sample-20201101.csv'\n",
        "  allData = pd.read_csv(url)\n",
        "\n",
        "  # Remove Bribri lines that have no English equivalent\n",
        "  pairs = allData.dropna()\n",
        "\n",
        "  # split into backtranslation, training, testing and validation sets\n",
        "  sampleSplit(pairs, useSynthData, portionRealData, inTrainSteps, percentBT)\n",
        "\n",
        "  if (useSynthData == 1):\n",
        "\n",
        "    # step 1: Generate Spanish-Bribri model that we will use to make synthetic Bribri sentences.\n",
        "    bpSpanishBribri()\n",
        "    preprocessPairs()\n",
        "    trainNMT(trainStepsForModels, validationStepsForModels, checkpointStepsForModels, '/content/spn-brb-log1.txt')\n",
        "    produceNMTTranslations(modelName, '/content/brbnmt-test-spn.txt', '/content/spn-brb-log2.txt')\n",
        "    getBlue('/content/brbnmt-test-brb.txt', '/content/spn-brb-log3.txt')\n",
        "    generateSynth(modelName, '/content/brbnmt-bt-spn.txt', '/content/synth-bribri-1.txt')\n",
        "\n",
        "  # step 2: Train a Bribri-Spanish model with just real data, to see the baseline performance.\n",
        "\n",
        "  bpBribriSpanish()\n",
        "  preprocessPairs()\n",
        "  trainNMT(trainStepsForModels, validationStepsForModels, checkpointStepsForModels, '/content/spn-brb-log4.txt')\n",
        "  produceNMTTranslations(modelName, '/content/brbnmt-test-brb.txt', '/content/spn-brb-log5.txt')\n",
        "  getBlue('/content/brbnmt-test-spn.txt', '/content/spn-brb-log6.txt')\n",
        "\n",
        "  if (useSynthData == 1):\n",
        "\n",
        "    # Step 3: Merge Bribri synthetic data with Bribri real data and re-train a model with the real and synthetic Bribri combined.\n",
        "    mergeSynthSentences('/content/synth-bribri-1.txt')\n",
        "    bpBribriSpanish()\n",
        "    preprocessPairs()\n",
        "    trainNMT(trainStepsForModels, validationStepsForModels, checkpointStepsForModels, '/content/spn-brb-log7.txt')\n",
        "    produceNMTTranslations(modelName, '/content/brbnmt-test-brb.txt', '/content/spn-brb-log8.txt')\n",
        "    getBlue('/content/brbnmt-test-spn.txt', '/content/spn-brb-log9.txt')\n",
        "\n",
        "    # Step 4: Make a new model for Spanish-Bribri training and regenerate the synthetic Bribri sentences\n",
        "    bpSpanishBribri()\n",
        "    preprocessPairs()\n",
        "    trainNMT(trainStepsForModels, validationStepsForModels, checkpointStepsForModels, '/content/spn-brb-log10.txt')\n",
        "    produceNMTTranslations(modelName, '/content/brbnmt-test-spn.txt', '/content/spn-brb-log11.txt')\n",
        "    getBlue('/content/brbnmt-test-brb.txt', '/content/spn-brb-log12.txt')\n",
        "    generateSynth(modelName, '/content/brbnmt-bt-spn.txt', '/content/synth-bribri-2.txt')\n",
        "\n",
        "    # Step 5: Merge second Bribri synthetic data with Bribri real data and re-train a model with real and synthetic Bribri combined.\n",
        "    mergeSynthSentences('/content/synth-bribri-2.txt')\n",
        "    bpBribriSpanish()\n",
        "    preprocessPairs()\n",
        "    trainNMT(trainStepsForModels, validationStepsForModels, checkpointStepsForModels, '/content/spn-brb-log13.txt')\n",
        "    produceNMTTranslations(modelName, '/content/brbnmt-test-brb.txt', '/content/spn-brb-log14.txt')\n",
        "    getBlue('/content/brbnmt-test-spn.txt', '/content/spn-brb-log15.txt')\n",
        "\n",
        "  # step 6: get report\n",
        "\n",
        "  from google.colab import files\n",
        "  !rm logs.txt\n",
        "\n",
        "  now = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "  logName = \"logs-BT\" +  str(int(percentBT*100)) + \"-\" + now + \".txt\"\n",
        "\n",
        "  if (useSynthData == 1):\n",
        "\n",
        "    !cat <(echo '--- Log metadata ---') brbnmt-meta.txt \\\n",
        "      <(echo '--- Training first SPA-BRI model ---') spn-brb-log1.txt \\\n",
        "      <(echo '--- Test first SPA-BRI model ---') spn-brb-log2.txt \\\n",
        "      <(echo '--- BLEU first SPA-BRI model ---') spn-brb-log3.txt \\\n",
        "      <(echo '--- Training BRI-SPA realData model ---') spn-brb-log4.txt \\\n",
        "      <(echo '--- Test BRI-SPA realData model ---') spn-brb-log5.txt \\\n",
        "      <(echo '--- BLEU BRI-SPA realData model ---') spn-brb-log6.txt \\\n",
        "      <(echo '--- Training BRI-SPA synth1 model ---') spn-brb-log7.txt \\\n",
        "      <(echo '--- Test BRI-SPA synth1 model ---') spn-brb-log8.txt \\\n",
        "      <(echo '--- BLEU BRI-SPA synth1 model ---') spn-brb-log9.txt \\\n",
        "      <(echo '--- Training second SPA-BRI model ---') spn-brb-log10.txt \\\n",
        "      <(echo '--- Test second SPA-BRI model ---') spn-brb-log11.txt \\\n",
        "      <(echo '--- BLEU second SPA-BRI model ---') spn-brb-log12.txt \\\n",
        "      <(echo '--- Training BRI-SPA synth2 model ---') spn-brb-log13.txt \\\n",
        "      <(echo '--- Test BRI-SPA synth2 model ---') spn-brb-log14.txt \\\n",
        "      <(echo '--- BLEU BRI-SPA synth2 model ---') spn-brb-log15.txt \\\n",
        "      <(echo '--- Bribri realData training sentences ---') brbnmt-train-brb-original.txt \\\n",
        "      <(echo '--- Bribri synth1 sentences ---') synth-bribri-1.txt \\\n",
        "      <(echo '--- Bribri synth2 sentences ---') synth-bribri-2.txt \\\n",
        "      <(echo '--- Spanish training sentences ---') brbnmt-train-spn.txt \\\n",
        "      >> $logName\n",
        "\n",
        "  else:\n",
        "\n",
        "    !cat <(echo '--- Log metadata ---') brbnmt-meta.txt \\\n",
        "      <(echo '--- Training BRI-SPA realData model ---') spn-brb-log4.txt \\\n",
        "      <(echo '--- Test BRI-SPA realData model ---') spn-brb-log5.txt \\\n",
        "      <(echo '--- BLEU BRI-SPA realData model ---') spn-brb-log6.txt \\\n",
        "      >> $logName\n",
        "\n",
        "\n",
        "  files.download(logName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxrG8iBHwrO2"
      },
      "source": [
        "run the code a couple of times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7e6RcETwsgq"
      },
      "source": [
        "#isaac: 5 x condition2 (3K real, no synth)\n",
        "\n",
        "for i in range(5):\n",
        "  runTraining(0, 0.5, 4000, 4000, 4000, 'OpenNMT-py/data/model/model_step_4000.pt', -1)  # no synth, 3K real"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}